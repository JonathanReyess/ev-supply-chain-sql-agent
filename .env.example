# ===========================================
# EV Supply Chain SQL Agent - Gemini Configuration
# ===========================================

# Database path
DB_PATH=./data/ev_supply_chain.db

# ===========================================
# GEMINI/LLM CONFIGURATION
# ===========================================

# Provider: Use Gemini for all LLM operations
LLM_PROVIDER=gemini

# Enable LLM router for intelligent query routing
USE_LLM_ROUTER=true

# Gemini API Key (required)
# Get your key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_gemini_api_key_here

# Alternative key names (any of these will work)
# GEMINI_API_KEY=your_gemini_api_key_here
# LLM_API_KEY=your_gemini_api_key_here

# Gemini model to use
GEMINI_MODEL=gemini-2.0-flash-exp
LLM_MODEL=gemini-2.0-flash-exp

# ===========================================
# NLP ENGINE CONFIGURATION
# ===========================================

# Enable advanced NLP engine
USE_ADVANCED_NLP=true

# LLM routing strategy
# false = try patterns first, use LLM as fallback (recommended)
# true = use LLM first (higher accuracy but slower)
LLM_FIRST=false

# ===========================================
# PERFORMANCE TUNING
# ===========================================

# LLM latency budget (milliseconds)
LLM_LATENCY_MS=400

# Maximum wait time for dock assignments (minutes)
MAX_WAIT_MIN=30

# ===========================================
# EVALUATION CONFIGURATION
# ===========================================

# Judge model for evaluations (uses Gemini)
JUDGE_MODEL=gemini-2.0-flash-exp

# ===========================================
# DEBUGGING (Optional)
# ===========================================

# Enable debug logging for LLM router
# DEBUG_LLM_ROUTER=true

# ===========================================
# NOTES
# ===========================================
# 1. Copy this file to .env and replace "your_gemini_api_key_here" with your actual key
# 2. Available Gemini models:
#    - gemini-2.0-flash-exp (recommended, fast and accurate)
#    - gemini-pro (stable)
#    - gemini-pro-latest (latest stable version)
# 3. All LLM operations (routing, NLP, evaluation) will use Gemini
# 4. No OpenAI key needed with this configuration
